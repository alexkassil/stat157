{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Homework 1 - Berkeley STAT 157\n",
    "\n",
    "Handout 1/22/2017, due 1/29/2017 by 4pm in Git by committing to your repository. Please ensure that you add the TA Git account to your repository.\n",
    "\n",
    "1. Write all code in the notebook.\n",
    "1. Write all text in the notebook. You can use MathJax to insert math or generic Markdown to insert figures (it's unlikely you'll need the latter). \n",
    "1. **Execute** the notebook and **save** the results.\n",
    "1. To be safe, print the notebook as PDF and add it to the repository, too. Your repository should contain two files: ``homework1.ipynb`` and ``homework1.pdf``. \n",
    "\n",
    "The TA will return the corrected and annotated homework back to you via Git (please give `rythei` access to your repository)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T19:57:47.188990Z",
     "start_time": "2019-01-22T19:57:46.107420Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Something is wrong with the numpy installation. While importing we detected an older version of numpy in ['/home/alexkassil/.local/lib/python3.6/site-packages/numpy']. One method of fixing this is to repeatedly uninstall numpy until none is found, then reinstall this version.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1d04cac3a20c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/mxnet/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu_pinned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/mxnet/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassproperty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_metaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_MXClassPropertyMetaClass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LIB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplatform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibinfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;34m\"numpy in {}. One method of fixing this is to repeatedly uninstall \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \"numpy until none is found, then reinstall this version.\")\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumerictypes\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Something is wrong with the numpy installation. While importing we detected an older version of numpy in ['/home/alexkassil/.local/lib/python3.6/site-packages/numpy']. One method of fixing this is to repeatedly uninstall numpy until none is found, then reinstall this version."
     ]
    }
   ],
   "source": [
    "from mxnet import ndarray as nd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Speedtest for vectorization\n",
    "\n",
    "Your goal is to measure the speed of linear algebra operations for different levels of vectorization. You need to use `wait_to_read()` on the output to ensure that the result is computed completely, since NDArray uses asynchronous computation. Please see http://beta.mxnet.io/api/ndarray/_autogen/mxnet.ndarray.NDArray.wait_to_read.html for details. \n",
    "\n",
    "1. Construct two matrices $A$ and $B$ with Gaussian random entries of size $4096 \\times 4096$. \n",
    "1. Compute $C = A B$ using matrix-matrix operations and report the time. \n",
    "1. Compute $C = A B$, treating $A$ as a matrix but computing the result for each column of $B$ one at a time. Report the time.\n",
    "1. Compute $C = A B$, treating $A$ and $B$ as collections of vectors. Report the time.\n",
    "1. Bonus question - what changes if you execute this on a GPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "nd_a1 = mx.nd.array([[0, 0, 0]])\n",
    "# nd_a1 = mx.nd.empty((0,3))\n",
    "nd_a1 = mx.nd.concat(nd_a1, mx.nd.array([[1,2,3],[4,5,6]]), dim=0)\n",
    "nd_a1 = mx.nd.concat(nd_a1, mx.nd.array([[7, 8, 9]]), dim=0)\n",
    "print(\"\\nnd_a1\", nd_a1)\n",
    "print(nd_a1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[33. 52.]\n",
      " [41. 64.]]\n",
      "<NDArray 2x2 @cpu(0)>\n",
      "\n",
      "[[33. 41.]]\n",
      "<NDArray 1x2 @cpu(0)>\n",
      "\n",
      "[[33. 41.]\n",
      " [-1. -1.]]\n",
      "<NDArray 2x2 @cpu(0)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[33. 52.]\n",
       " [41. 64.]]\n",
       "<NDArray 2x2 @cpu(0)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = nd.array([[1, 6],\n",
    "              [2, 7]])\n",
    "B = nd.array([[3, 4],\n",
    "              [5, 8]])\n",
    "print(nd.dot(A, B))\n",
    "C = nd.dot(A, B[:, 0]).expand_dims(0)\n",
    "print(C)\n",
    "C = nd.concat(C, nd.array([[-1, -1]]), dim=0)\n",
    "print(C)\n",
    "D = nd.dot(A[0, :], B[:, 0]).expand_dims(0)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        if i != 0 or j != 0:\n",
    "            D = nd.concat(D, nd.dot(A[i, :], B[:, j]).expand_dims(0), dim=0)\n",
    "D.reshape(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for 1.2 0.31929516792297363\n"
     ]
    }
   ],
   "source": [
    "A = nd.random.normal(shape=(4096,4096))\n",
    "B = nd.random.normal(shape=(4096,4096))\n",
    "tic = time()\n",
    "C = nd.dot(A, B)\n",
    "C.wait_to_read()\n",
    "print(\"Time for 1.2\", time()-tic)\n",
    "# Source https://stackoverflow.com/questions/49873467/how-to-append-a-element-to-mxnet-ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 4096)\n",
      "Time for 1.3 27.757354259490967\n"
     ]
    }
   ],
   "source": [
    "tic = time()\n",
    "C = nd.dot(A, B[:, 0]).expand_dims(0)\n",
    "for i in range(1, 4096):\n",
    "    C = nd.concat(C, nd.dot(A, B[:, i]).expand_dims(0), dim=0)\n",
    "C = C.T\n",
    "print(C.shape)\n",
    "C.wait_to_read()\n",
    "print(\"Time for 1.3\", time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for 1.4 6639.831993341446\n"
     ]
    }
   ],
   "source": [
    "tic = time()\n",
    "C = nd.empty((4096, 4096))\n",
    "for i in range(4096):\n",
    "    for j in range(4096):\n",
    "        C[i, j] = nd.dot(A[i, :], B[:, j])\n",
    "C.wait_to_read()\n",
    "print(\"Time for 1.4\", time()-tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Semidefinite Matrices\n",
    "\n",
    "Assume that $A \\in \\mathbb{R}^{m \\times n}$ is an arbitrary matrix and that $D \\in \\mathbb{R}^{n \\times n}$ is a diagonal matrix with nonnegative entries. \n",
    "\n",
    "1. Prove that $B = A D A^\\top$ is a positive semidefinite matrix. \n",
    "1. When would it be useful to work with $B$ and when is it better to use $A$ and $D$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1) \n",
    "To show $$ADA^{T}$$ is a positive semidefinite (psd) matrix, we must show that $$x^{T}ADA^{T}x >= 0 \\space \\forall x \\epsilon R^{n}$$\n",
    "\n",
    "$$x^{T}ADA^{T}x = (A^{T}x)^TD(A^Tx)$$\n",
    "Substitue $z = A^Tx$ we get $$z^TDz$$\n",
    "$D$ is psd, since the sum of it's diagonal entries is equal to the sum of its eigenvalues and is nonnegative, so $z^TDz >= 0$ for all z, so $ADA^T$ is positive semidefinite. QED\n",
    "\n",
    "2.2) It is useful to work with B since it is a square, positiive semidefinite matrix. It seems to hold all the information of A but transform an arbitrary matrix into one with nice properties. When we do SVD we look at $AA^T$, so now we can specify which entries to leave out by setting some of $D$'s diagonal values to zero or which entries to modify by setting $D$'s diagonal values to not $1$.\n",
    "\n",
    "If say $A$ is a data matrix, it is better to work with it directly when training a machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MXNet on GPUs\n",
    "\n",
    "1. Install GPU drivers (if needed)\n",
    "1. Install MXNet on a GPU instance\n",
    "1. Display `!nvidia-smi`\n",
    "1. Create a $2 \\times 2$ matrix on the GPU and print it. See http://d2l.ai/chapter_deep-learning-computation/use-gpu.html for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 15 21:16:45 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:04:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    31W / 250W |    263MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE...  Off  | 00000000:05:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    26W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla P100-PCIE...  Off  | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    32W / 250W |   2635MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla P100-PCIE...  Off  | 00000000:09:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    30W / 250W |    327MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla P100-PCIE...  Off  | 00000000:84:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    31W / 250W |    827MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla P100-PCIE...  Off  | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   61C    P0   168W / 250W |   7847MiB / 16280MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla P100-PCIE...  Off  | 00000000:88:00.0 Off |                    0 |\n",
      "| N/A   58C    P0   183W / 250W |   8164MiB / 16280MiB |     97%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla P100-PCIE...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   65C    P0   197W / 250W |   5975MiB / 16280MiB |     97%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     31501      C   python3.6                                    253MiB |\n",
      "|    2     31501      C   python3.6                                   2625MiB |\n",
      "|    3      1341      C   ...e/tianruic/anaconda3/envs/tf/bin/python   317MiB |\n",
      "|    4     31501      C   python3.6                                    817MiB |\n",
      "|    5     31458      C   python3                                     7837MiB |\n",
      "|    6      1341      C   ...e/tianruic/anaconda3/envs/tf/bin/python   317MiB |\n",
      "|    6     19980      C   python3                                     7837MiB |\n",
      "|    7     31445      C   python3                                     5965MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "[21:16:46] src/resource.cc:153: GPU is not enabled\n\nStack trace returned 10 entries:\n[bt] (0) /home/alexkassil/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x23d55a) [0x7fd4c4aec55a]\n[bt] (1) /home/alexkassil/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x23dbc1) [0x7fd4c4aecbc1]\n[bt] (2) /home/alexkassil/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x32b0581) [0x7fd4c7b5f581]\n[bt] (3) /home/alexkassil/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::imperative::SetDependency(nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> >*, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> >*, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> >*, std::vector<unsigned int, std::allocator<unsigned int> >*, mxnet::DispatchMode)+0x134f) [0x7fd4c74d5b4f]\n[bt] (4) /home/alexkassil/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::Imperative::InvokeOp(mxnet::Context const&, nnvm::NodeAttrs const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, mxnet::DispatchMode, mxnet::OpStatePtr)+0x18a) [0x7fd4c74d620a]\n[bt] (5) /home/alexkassil/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::Imperative::Invoke(mxnet::Context const&, nnvm::NodeAttrs const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&)+0x38c) [0x7fd4c74d713c]\n[bt] (6) /home/alexkassil/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2b2d8b9) [0x7fd4c73dc8b9]\n[bt] (7) /home/alexkassil/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(MXImperativeInvokeEx+0x6f) [0x7fd4c73dceaf]\n[bt] (8) /home/alexkassil/miniconda3/envs/gluon/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7fd539274ec0]\n[bt] (9) /home/alexkassil/miniconda3/envs/gluon/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7fd53927487d]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-747f5520fffa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/mxnet/ndarray/random.py\u001b[0m in \u001b[0;36mnormal\u001b[0;34m(loc, scale, shape, dtype, ctx, out, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \"\"\"\n\u001b[1;32m    151\u001b[0m     return _random_helper(_internal._random_normal, _internal._sample_normal,\n\u001b[0;32m--> 152\u001b[0;31m                           [loc, scale], shape, dtype, ctx, out, kwargs)\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/mxnet/ndarray/random.py\u001b[0m in \u001b[0;36m_random_helper\u001b[0;34m(random, sampler, params, shape, dtype, ctx, out, kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;34m\"Distribution parameters must all have the same type, but got \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;34m\"both %s and %s.\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     raise ValueError(\"Distribution parameters must be either NDArray or numbers, \"\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/mxnet/ndarray/register.py\u001b[0m in \u001b[0;36m_random_normal\u001b[0;34m(loc, scale, shape, ctx, dtype, out, name, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/mxnet/_ctypes/ndarray.py\u001b[0m in \u001b[0;36m_imperative_invoke\u001b[0;34m(handle, ndargs, keys, vals, out)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         ctypes.byref(out_stypes)))\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moriginal_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \"\"\"\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: [21:16:46] src/resource.cc:153: GPU is not enabled\n\nStack trace returned 10 entries:\n[bt] (0) /home/alexkassil/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x23d55a) [0x7fd4c4aec55a]\n[bt] (1) /home/alexkassil/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x23dbc1) [0x7fd4c4aecbc1]\n[bt] (2) /home/alexkassil/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x32b0581) [0x7fd4c7b5f581]\n[bt] (3) /home/alexkassil/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::imperative::SetDependency(nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> >*, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> >*, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> >*, std::vector<unsigned int, std::allocator<unsigned int> >*, mxnet::DispatchMode)+0x134f) [0x7fd4c74d5b4f]\n[bt] (4) /home/alexkassil/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::Imperative::InvokeOp(mxnet::Context const&, nnvm::NodeAttrs const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, mxnet::DispatchMode, mxnet::OpStatePtr)+0x18a) [0x7fd4c74d620a]\n[bt] (5) /home/alexkassil/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::Imperative::Invoke(mxnet::Context const&, nnvm::NodeAttrs const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&)+0x38c) [0x7fd4c74d713c]\n[bt] (6) /home/alexkassil/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2b2d8b9) [0x7fd4c73dc8b9]\n[bt] (7) /home/alexkassil/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(MXImperativeInvokeEx+0x6f) [0x7fd4c73dceaf]\n[bt] (8) /home/alexkassil/miniconda3/envs/gluon/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7fd539274ec0]\n[bt] (9) /home/alexkassil/miniconda3/envs/gluon/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7fd53927487d]\n\n"
     ]
    }
   ],
   "source": [
    "nd.random.normal(shape=(2,2), ctx=mx.gpu())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. NDArray and NumPy \n",
    "\n",
    "Your goal is to measure the speed penalty between MXNet Gluon and Python when converting data between both. We are going to do this as follows:\n",
    "\n",
    "1. Create two Gaussian random matrices $A, B$ of size $4096 \\times 4096$ in NDArray. \n",
    "1. Compute a vector $\\mathbf{c} \\in \\mathbb{R}^{4096}$ where $c_i = \\|A B_{i\\cdot}\\|^2$ where $\\mathbf{c}$ is a **NumPy** vector.\n",
    "\n",
    "To see the difference in speed due to Python perform the following two experiments and measure the time:\n",
    "\n",
    "1. Compute $\\|A B_{i\\cdot}\\|^2$ one at a time and assign its outcome to $\\mathbf{c}_i$ directly.\n",
    "1. Use an intermediate storage vector $\\mathbf{d}$ in NDArray for assignments and copy to NumPy at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for 4.1 3.652972936630249\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = nd.random.normal(shape=(4096, 4096), ctx=mx.gpu())\n",
    "B = nd.random.normal(shape=(4096, 4096), ctx=mx.gpu())\n",
    "c = np.zeros(4096)\n",
    "tic = time()\n",
    "for i in range(4096):\n",
    "    c[i] = (nd.dot(A, B[:, i]).norm() ** 2).asscalar()\n",
    "print(\"Time for 4.1\", time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for 4.1 1.4525656700134277\n"
     ]
    }
   ],
   "source": [
    "d = nd.zeros(4096, ctx=mx.gpu())\n",
    "tic = time()\n",
    "for i in range(4096):\n",
    "    d[i] = (nd.dot(A, B[:, i]).norm() ** 2)\n",
    "d = nd.dot(A, B).norm() ** 2\n",
    "c = d.asnumpy()\n",
    "print(\"Time for 4.1\", time()-tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Memory efficient computation\n",
    "\n",
    "We want to compute $C \\leftarrow A \\cdot B + C$, where $A, B$ and $C$ are all matrices. Implement this in the most memory efficient manner. Pay attention to the following two things:\n",
    "\n",
    "1. Do not allocate new memory for the new value of $C$.\n",
    "1. Do not allocate new memory for intermediate results if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = nd.empty((4096, 4096), ctx=mx.gpu())\n",
    "C += nd.dot(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Broadcast Operations\n",
    "\n",
    "In order to perform polynomial fitting we want to compute a design matrix $A$ with \n",
    "\n",
    "$$A_{ij} = x_i^j$$\n",
    "\n",
    "Our goal is to implement this **without a single for loop** entirely using vectorization and broadcast. Here $1 \\leq j \\leq 20$ and $x = \\{-10, -9.9, \\ldots 10\\}$. Implement code that generates such a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-1.0000000e+01  1.0000000e+02 -1.0000000e+03 ...  9.9999998e+17\n",
       "  -1.0000000e+19  1.0000000e+20]\n",
       " [-9.8999996e+00  9.8009995e+01 -9.7029889e+02 ...  8.3451318e+17\n",
       "  -8.2616803e+18  8.1790629e+19]\n",
       " [-9.8000002e+00  9.6040001e+01 -9.4119208e+02 ...  6.9513558e+17\n",
       "  -6.8123289e+18  6.6760824e+19]\n",
       " ...\n",
       " [ 9.6999998e+00  9.4089996e+01  9.1267297e+02 ...  5.7795107e+17\n",
       "   5.6061250e+18  5.4379413e+19]\n",
       " [ 9.8000002e+00  9.6040001e+01  9.4119208e+02 ...  6.9513558e+17\n",
       "   6.8123289e+18  6.6760824e+19]\n",
       " [ 9.8999996e+00  9.8009995e+01  9.7029889e+02 ...  8.3451318e+17\n",
       "   8.2616803e+18  8.1790629e+19]]\n",
       "<NDArray 200x20 @cpu(0)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nd.arange(-100, 101)/10\n",
    "A = x.reshape((200, 1)).broadcast_to((200, 20)) ** \\\n",
    "nd.arange(1, 21).broadcast_to((200, 20))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
